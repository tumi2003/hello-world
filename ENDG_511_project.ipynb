{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tumi2003/hello-world/blob/main/ENDG_511_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Dataset into a pandas Dataframe"
      ],
      "metadata": {
        "id": "vId41NnVfkkH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qW2CJPOmdOQM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22739792-c303-4de0-9c64-d96aaffb0c21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-82e464ca3e7d>:8: DtypeWarning: Columns (1,3,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_list = [pd.read_csv(f) for f in files]\n",
            "<ipython-input-20-82e464ca3e7d>:8: DtypeWarning: Columns (3,39,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_list = [pd.read_csv(f) for f in files]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2540047 entries, 0 to 2540046\n",
            "Data columns (total 49 columns):\n",
            " #   Column            Dtype  \n",
            "---  ------            -----  \n",
            " 0   srcip             object \n",
            " 1   sport             object \n",
            " 2   dstip             object \n",
            " 3   dsport            object \n",
            " 4   proto             object \n",
            " 5   state             object \n",
            " 6   dur               float64\n",
            " 7   sbytes            int64  \n",
            " 8   dbytes            int64  \n",
            " 9   sttl              int64  \n",
            " 10  dttl              int64  \n",
            " 11  sloss             int64  \n",
            " 12  dloss             int64  \n",
            " 13  service           object \n",
            " 14  Sload             float64\n",
            " 15  Dload             float64\n",
            " 16  Spkts             int64  \n",
            " 17  Dpkts             int64  \n",
            " 18  swin              int64  \n",
            " 19  dwin              int64  \n",
            " 20  stcpb             int64  \n",
            " 21  dtcpb             int64  \n",
            " 22  smeansz           int64  \n",
            " 23  dmeansz           int64  \n",
            " 24  trans_depth       int64  \n",
            " 25  res_bdy_len       int64  \n",
            " 26  Sjit              float64\n",
            " 27  Djit              float64\n",
            " 28  Stime             int64  \n",
            " 29  Ltime             int64  \n",
            " 30  Sintpkt           float64\n",
            " 31  Dintpkt           float64\n",
            " 32  tcprtt            float64\n",
            " 33  synack            float64\n",
            " 34  ackdat            float64\n",
            " 35  is_sm_ips_ports   int64  \n",
            " 36  ct_state_ttl      int64  \n",
            " 37  ct_flw_http_mthd  float64\n",
            " 38  is_ftp_login      float64\n",
            " 39  ct_ftp_cmd        object \n",
            " 40  ct_srv_src        int64  \n",
            " 41  ct_srv_dst        int64  \n",
            " 42  ct_dst_ltm        int64  \n",
            " 43  ct_src_ ltm       int64  \n",
            " 44  ct_src_dport_ltm  int64  \n",
            " 45  ct_dst_sport_ltm  int64  \n",
            " 46  ct_dst_src_ltm    int64  \n",
            " 47  attack_cat        object \n",
            " 48  Label             int64  \n",
            "dtypes: float64(12), int64(28), object(9)\n",
            "memory usage: 949.6+ MB\n",
            "None\n",
            "        srcip  sport          dstip dsport proto state       dur  sbytes  \\\n",
            "0  59.166.0.0   1390  149.171.126.6     53   udp   CON  0.001055     132   \n",
            "1  59.166.0.0  33661  149.171.126.9   1024   udp   CON  0.036133     528   \n",
            "2  59.166.0.6   1464  149.171.126.7     53   udp   CON  0.001119     146   \n",
            "3  59.166.0.5   3593  149.171.126.5     53   udp   CON  0.001209     132   \n",
            "4  59.166.0.3  49664  149.171.126.0     53   udp   CON  0.001169     146   \n",
            "\n",
            "   dbytes  sttl  ...  ct_ftp_cmd  ct_srv_src  ct_srv_dst ct_dst_ltm  \\\n",
            "0     164    31  ...           0           3           7          1   \n",
            "1     304    31  ...           0           2           4          2   \n",
            "2     178    31  ...           0          12           8          1   \n",
            "3     164    31  ...           0           6           9          1   \n",
            "4     178    31  ...           0           7           9          1   \n",
            "\n",
            "   ct_src_ ltm  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
            "0            3                 1                 1               1   \n",
            "1            3                 1                 1               2   \n",
            "2            2                 2                 1               1   \n",
            "3            1                 1                 1               1   \n",
            "4            1                 1                 1               1   \n",
            "\n",
            "   attack_cat  Label  \n",
            "0         NaN      0  \n",
            "1         NaN      0  \n",
            "2         NaN      0  \n",
            "3         NaN      0  \n",
            "4         NaN      0  \n",
            "\n",
            "[5 rows x 49 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load all dataset files\n",
        "files = [\"/content/drive/MyDrive/UNSW-NB15_1.csv\", \"/content/drive/MyDrive/UNSW-NB15_2.csv\", \"/content/drive/MyDrive/UNSW-NB15_3.csv\", \"/content/drive/MyDrive/UNSW-NB15_4.csv\"]\n",
        "df_list = [pd.read_csv(f) for f in files]\n",
        "\n",
        "# Combine all parts into a single DataFrame\n",
        "df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "# Display dataset info\n",
        "print(df.info())\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill in Missing Values\n"
      ],
      "metadata": {
        "id": "-YKST0puf2vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Fill or drop missing values (if any)\n",
        "df.fillna(0, inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tozKqv5yf0BB",
        "outputId": "46633529-62ab-43df-959e-503a74b1b074"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "srcip                     0\n",
            "sport                     0\n",
            "dstip                     0\n",
            "dsport                    0\n",
            "proto                     0\n",
            "state                     0\n",
            "dur                       0\n",
            "sbytes                    0\n",
            "dbytes                    0\n",
            "sttl                      0\n",
            "dttl                      0\n",
            "sloss                     0\n",
            "dloss                     0\n",
            "service                   0\n",
            "Sload                     0\n",
            "Dload                     0\n",
            "Spkts                     0\n",
            "Dpkts                     0\n",
            "swin                      0\n",
            "dwin                      0\n",
            "stcpb                     0\n",
            "dtcpb                     0\n",
            "smeansz                   0\n",
            "dmeansz                   0\n",
            "trans_depth               0\n",
            "res_bdy_len               0\n",
            "Sjit                      0\n",
            "Djit                      0\n",
            "Stime                     0\n",
            "Ltime                     0\n",
            "Sintpkt                   0\n",
            "Dintpkt                   0\n",
            "tcprtt                    0\n",
            "synack                    0\n",
            "ackdat                    0\n",
            "is_sm_ips_ports           0\n",
            "ct_state_ttl              0\n",
            "ct_flw_http_mthd    1348145\n",
            "is_ftp_login        1429879\n",
            "ct_ftp_cmd                0\n",
            "ct_srv_src                0\n",
            "ct_srv_dst                0\n",
            "ct_dst_ltm                0\n",
            "ct_src_ ltm               0\n",
            "ct_src_dport_ltm          0\n",
            "ct_dst_sport_ltm          0\n",
            "ct_dst_src_ltm            0\n",
            "attack_cat          2218764\n",
            "Label                     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)  # Display all column names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2afA_iKgdOS",
        "outputId": "38cb4cad-9a0e-4d35-f6b1-fdb4858f0ed3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['srcip', 'sport', 'dstip', 'dsport', 'proto', 'state', 'dur', 'sbytes',\n",
            "       'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'service', 'Sload', 'Dload',\n",
            "       'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz',\n",
            "       'dmeansz', 'trans_depth', 'res_bdy_len', 'Sjit', 'Djit', 'Stime',\n",
            "       'Ltime', 'Sintpkt', 'Dintpkt', 'tcprtt', 'synack', 'ackdat',\n",
            "       'is_sm_ips_ports', 'ct_state_ttl', 'ct_flw_http_mthd', 'is_ftp_login',\n",
            "       'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ ltm',\n",
            "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'attack_cat',\n",
            "       'Label'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode categorical columns\n",
        "categorical_columns = ['srcip','proto', 'service', 'state','dstip']  # Example categorical features\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "for col in categorical_columns:\n",
        "    df[col] = encoder.fit_transform(df[col])\n"
      ],
      "metadata": {
        "id": "Dx2kauwBgI8w"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Select numeric features (excluding label)\n",
        "features = df.drop(columns=['Label','attack_cat','Stime','Ltime','sport','dsport','ct_ftp_cmd'])  # 'label' is the attack/normal classification column\n",
        "\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "df_scaled = scaler.fit_transform(features)\n",
        "\n",
        "# Convert back to DataFrame\n",
        "df_scaled = pd.DataFrame(df_scaled, columns=features.columns)\n"
      ],
      "metadata": {
        "id": "vFSGcOrCgKIx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define X (features) and y (labels)\n",
        "X = df_scaled\n",
        "y = df['Label']  # '1' for attack, '0' for normal\n",
        "\n",
        "# Split dataset (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(\"Training set size:\", X_train.shape)\n",
        "print(\"Testing set size:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfd_O9lVp-7H",
        "outputId": "d9babdab-0f07-4980-b973-62d301609a07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: (2032037, 42)\n",
            "Testing set size: (508010, 42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Define and train model\n",
        "iso_forest = IsolationForest(n_estimators=100, contamination=0.05, random_state=42)\n",
        "iso_forest.fit(X_train)\n",
        "\n",
        "# Predict anomalies (-1 = anomaly, 1 = normal)\n",
        "y_pred = iso_forest.predict(X_test)\n",
        "\n",
        "# Convert predictions to binary format (1 = anomaly, 0 = normal)\n",
        "y_pred_binary = [1 if pred == -1 else 0 for pred in y_pred]\n"
      ],
      "metadata": {
        "id": "dj9TY-CKp_Ff"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "# Define input shape\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "# Build Autoencoder\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "encoded = Dense(64, activation=\"relu\")(input_layer)\n",
        "encoded = Dense(32, activation=\"relu\")(encoded)\n",
        "decoded = Dense(64, activation=\"relu\")(encoded)\n",
        "decoded = Dense(input_dim, activation=\"sigmoid\")(decoded)\n",
        "\n",
        "autoencoder = Model(input_layer, decoded)\n",
        "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "# Train Autoencoder\n",
        "autoencoder.fit(X_train, X_train, epochs=20, batch_size=32, validation_data=(X_test, X_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqpq8sooqedE",
        "outputId": "efea96e9-5de3-497d-86b2-96f2269212d0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m63502/63502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 3ms/step - loss: 0.0014 - val_loss: 5.7469e-05\n",
            "Epoch 2/20\n",
            "\u001b[1m63502/63502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 3ms/step - loss: 3.5032e-05 - val_loss: 3.1311e-05\n",
            "Epoch 3/20\n",
            "\u001b[1m63502/63502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 3ms/step - loss: 2.7589e-05 - val_loss: 2.5834e-05\n",
            "Epoch 4/20\n",
            "\u001b[1m63502/63502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 3ms/step - loss: 2.4826e-05 - val_loss: 2.4567e-05\n",
            "Epoch 5/20\n",
            "\u001b[1m63502/63502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 3ms/step - loss: 2.3282e-05 - val_loss: 2.5172e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m63502/63502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 3ms/step - loss: 2.1507e-05 - val_loss: 1.9739e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m63502/63502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 3ms/step - loss: 1.9650e-05 - val_loss: 2.0682e-05\n",
            "Epoch 8/20\n",
            "\u001b[1m63502/63502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 3ms/step - loss: 1.9053e-05 - val_loss: 1.3717e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m63502/63502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3ms/step - loss: 1.2554e-05 - val_loss: 9.6822e-06\n",
            "Epoch 10/20\n",
            "\u001b[1m63502/63502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 3ms/step - loss: 1.1546e-05 - val_loss: 9.8715e-06\n",
            "Epoch 11/20\n",
            "\u001b[1m63502/63502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 3ms/step - loss: 1.0697e-05 - val_loss: 1.3476e-05\n",
            "Epoch 12/20\n",
            "\u001b[1m63502/63502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 3ms/step - loss: 1.0618e-05 - val_loss: 1.0376e-05\n",
            "Epoch 13/20\n",
            "\u001b[1m63502/63502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 3ms/step - loss: 9.8021e-06 - val_loss: 8.9256e-06\n",
            "Epoch 14/20\n",
            "\u001b[1m63502/63502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 3ms/step - loss: 9.5455e-06 - val_loss: 1.1112e-05\n",
            "Epoch 15/20\n",
            "\u001b[1m63502/63502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 3ms/step - loss: 9.5841e-06 - val_loss: 1.0532e-05\n",
            "Epoch 16/20\n",
            "\u001b[1m63502/63502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 3ms/step - loss: 9.2878e-06 - val_loss: 1.2886e-05\n",
            "Epoch 17/20\n",
            "\u001b[1m63502/63502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 3ms/step - loss: 9.0030e-06 - val_loss: 1.1130e-05\n",
            "Epoch 18/20\n",
            "\u001b[1m63502/63502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 3ms/step - loss: 8.8624e-06 - val_loss: 9.2964e-06\n",
            "Epoch 19/20\n",
            "\u001b[1m63502/63502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 3ms/step - loss: 8.6057e-06 - val_loss: 1.3289e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m63502/63502\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 3ms/step - loss: 9.2837e-06 - val_loss: 8.4531e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e912c15ecd0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Evaluate Isolation Forest\n",
        "print(\"Isolation Forest Results:\")\n",
        "print(classification_report(y_test, y_pred_binary))\n",
        "\n",
        "# Evaluate Autoencoder (Reconstruction Error)\n",
        "reconstructions = autoencoder.predict(X_test)\n",
        "mse = ((X_test - reconstructions) ** 2).mean(axis=1)\n",
        "\n",
        "# Set threshold for anomaly detection\n",
        "threshold = mse.mean() + 2 * mse.std()\n",
        "y_pred_autoencoder = [1 if error > threshold else 0 for error in mse]\n",
        "\n",
        "print(\"Autoencoder Results:\")\n",
        "print(classification_report(y_test, y_pred_autoencoder))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjgW1hZrGaqA",
        "outputId": "1273ef2e-9b76-483f-a9be-e48ed68de383"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Isolation Forest Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.96      0.92    443753\n",
            "           1       0.23      0.09      0.13     64257\n",
            "\n",
            "    accuracy                           0.85    508010\n",
            "   macro avg       0.56      0.52      0.52    508010\n",
            "weighted avg       0.80      0.85      0.82    508010\n",
            "\n",
            "\u001b[1m15876/15876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1ms/step\n",
            "Autoencoder Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93    443753\n",
            "           1       0.51      0.00      0.01     64257\n",
            "\n",
            "    accuracy                           0.87    508010\n",
            "   macro avg       0.69      0.50      0.47    508010\n",
            "weighted avg       0.83      0.87      0.82    508010\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Convert Isolation Forest output (-1 = anomaly, 1 = normal) to (1 = anomaly, 0 = normal)\n",
        "y_pred = [1 if pred == -1 else 0 for pred in iso_forest.predict(X_test)]\n",
        "\n",
        "# Compute Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4x3MowsbX7nO",
        "outputId": "03a8f3df-586f-43c9-8150-cc80b63d9ed1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8468\n",
            "Confusion Matrix:\n",
            "[[424219  19534]\n",
            " [ 58280   5977]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get model reconstructions\n",
        "reconstructions = autoencoder.predict(X_test)\n",
        "\n",
        "# Compute Mean Squared Error (MSE)\n",
        "mse = np.mean(np.power(X_test - reconstructions, 2), axis=1)\n",
        "\n",
        "# Set threshold (mean + 2 * standard deviation)\n",
        "threshold = mse.mean() + 2 * mse.std()\n",
        "\n",
        "# Predict anomalies\n",
        "y_pred_autoencoder = [1 if error > threshold else 0 for error in mse]\n",
        "\n",
        "# Compute Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_autoencoder)\n",
        "print(f\"Autoencoder Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7emD1hWYSCA",
        "outputId": "f0f95e80-6494-4313-ae7f-0416b1d5c505"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15876/15876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1ms/step\n",
            "Autoencoder Accuracy: 0.8735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained Isolation Forest model\n",
        "joblib.dump(iso_forest, \"isolation_forest_model.pkl\")\n",
        "\n",
        "print(\"Model saved as isolation_forest_model.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0zqzRPsU-QB",
        "outputId": "ce8bce09-f200-40b8-f210-b36ac8331d70"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as isolation_forest_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Autoencoder model in TensorFlow format\n",
        "autoencoder.save(\"autoencoder_model.h5\")\n",
        "\n",
        "print(\"Model saved as autoencoder_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT_JT5shVHJ3",
        "outputId": "961f615c-e338-41fe-8093-64f7d198d33f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as autoencoder_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load trained Isolation Forest model\n",
        "iso_forest = joblib.load(\"isolation_forest_model.pkl\")\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.json\n",
        "    features = data['features']\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = iso_forest.predict([features])\n",
        "    anomaly = 1 if prediction[0] == -1 else 0\n",
        "\n",
        "    return jsonify({'anomaly': anomaly})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(port=5000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBOSDFRkGjjm",
        "outputId": "0045aeec-fb79-47aa-ed86-aebdc1debd11"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}